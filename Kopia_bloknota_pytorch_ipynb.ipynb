{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sepren/Artificial-intelligence-specialist/blob/main/Kopia_bloknota_pytorch_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIRLmdneeGtK",
        "outputId": "1e27954f-293c-4dc5-90a3-6be6dfc3ce66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch===1.13 (from versions: 1.7.1, 1.8.0, 1.8.1, 1.9.0, 1.9.1, 1.10.0, 1.10.1, 1.10.2, 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch===1.13\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#pip install torch===1.13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "MWSzVL5B6MKs"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Then, you can import the libraries and define the ResNet model and TripletLoss function:\n",
        "\"\"\"\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "import numpy as np\n",
        "\n",
        "class ResNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet, self).__init__()\n",
        "        # self.resnet = torchvision.models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
        "        self.resnet = torchvision.models.resnet18(pretrained=True)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.fc = torch.nn.Linear(1000, 84)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet(x)\n",
        "        x = torch.nn.functional.normalize(x, dim=1)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class TripletLoss(torch.nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, anchor, positive, negative):\n",
        "        dist_pos = torch.nn.functional.pairwise_distance(anchor, positive)\n",
        "        dist_neg = torch.nn.functional.pairwise_distance(anchor, negative)\n",
        "        loss = torch.nn.functional.relu(dist_pos - dist_neg + self.margin)\n",
        "        return loss.mean()\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOAvv1gPeGtO"
      },
      "outputs": [],
      "source": [
        "class Mapping:\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "eFcHnkGl6cCZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\"\"\"\n",
        "Next, you need to define a function that loads the prewar photos of landmarks from a file path:\n",
        "\"\"\"\n",
        "def load_dataset(dataset_path):\n",
        "    dataset = []\n",
        "    # Tip: Use os.walk (!)\n",
        "    # TODO: fix\n",
        "    for file_path in os.listdir(dataset_path):\n",
        "        img = Image.open(os.path.join(dataset_path, file_path))\n",
        "        dataset.append((img, file_path))\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMtKJ7WkPVJq"
      },
      "outputs": [],
      "source": [
        "# DATASET_PATH = '/content/drive/MyDrive/Archive_project/Памятник Фридриху Вильгельму III'\n",
        "\n",
        "# test_dataset = load_dataset(DATASET_PATH)\n",
        "\n",
        "# test_dataset[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "91_2qxW06e5D"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def train_model(model, criterion, optimizer, dataloader, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs) in enumerate(tqdm(dataloader)):\n",
        "            inputs_0 = inputs[0].to(device)\n",
        "            inputs_1 = inputs[1].to(device)\n",
        "            inputs_2 = inputs[2].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs_0 = model(inputs_0)\n",
        "            outputs_1 = model(inputs_1)\n",
        "            outputs_2 = model(inputs_2)\n",
        "            loss = criterion(outputs_0, outputs_1, outputs_2)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        epoch_loss = running_loss / len(dataloader)\n",
        "        print('Epoch {}/{} Loss: {:.4f}'.format(epoch+1, num_epochs, epoch_loss))\n",
        "\n",
        "\n",
        "# [image, label] [0 ... N] N - кол-во размеченных достоприм.\n",
        "# \n",
        "\n",
        "# Split the dataset into triplets\n",
        "# TODO: Переделать, оптимизировать O(N^2) не годится!\n",
        "def create_triplets(dataset):\n",
        "    triplet_dataset = []\n",
        "    for i in range(len(dataset)):\n",
        "        anchor, anchor_label = dataset[i]\n",
        "        pos_indices = np.where(np.array(dataset.targets) == anchor_label)[0]\n",
        "        neg_indices = np.where(np.array(dataset.targets) != anchor_label)[0]\n",
        "        if len(pos_indices) < 2 or len(neg_indices) < 1: # ?\n",
        "            continue\n",
        "        positive_idx = np.random.choice(pos_indices)\n",
        "        negative_idx = np.random.choice(neg_indices)\n",
        "        positive = dataset[positive_idx][0]\n",
        "        negative = dataset[negative_idx][0]\n",
        "        triplet_dataset.append((anchor, positive, negative))\n",
        "    return triplet_dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaJmvyoOeTn_",
        "outputId": "db72557e-7990-46e8-f3c3-5eac0636fafa"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "WB0PZc7dXWxu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "a8068d0f-a741-44c2-dcef-37c8d2067776"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-b234e99e7ea8>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;31m# is potentially overridden and thus could have a different logic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The class_to_idx parameter cannot be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mextensions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"Supported extensions are: {extensions if isinstance(extensions, str) else ', '.join(extensions)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Found no valid file for the classes .ipynb_checkpoints. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = '/content/drive/MyDrive/Photo_Kenigsberg/1_class'\n",
        "\n",
        "\n",
        "\n",
        "# Load the face dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    # transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# [3, width, height] -> [1, 224, 224] -> \n",
        "\n",
        "DATASET_PATH\n",
        "train_dataset = torchvision.datasets.ImageFolder(root=DATASET_PATH, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s5Rwd18Xh-p",
        "outputId": "eb9f4ce7-b0c0-4cbb-a0a5-15e176abde2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 74,\n",
              "         1: 201,\n",
              "         2: 14,\n",
              "         3: 44,\n",
              "         4: 11,\n",
              "         5: 38,\n",
              "         6: 25,\n",
              "         7: 18,\n",
              "         8: 53,\n",
              "         9: 30,\n",
              "         10: 7,\n",
              "         11: 7,\n",
              "         12: 50,\n",
              "         13: 117,\n",
              "         14: 6,\n",
              "         15: 5,\n",
              "         16: 178,\n",
              "         17: 59,\n",
              "         18: 14,\n",
              "         19: 11,\n",
              "         20: 23,\n",
              "         21: 242,\n",
              "         22: 163,\n",
              "         23: 31,\n",
              "         24: 42,\n",
              "         25: 15,\n",
              "         26: 3,\n",
              "         27: 8,\n",
              "         28: 25,\n",
              "         29: 7,\n",
              "         30: 14,\n",
              "         31: 58,\n",
              "         32: 107,\n",
              "         33: 54,\n",
              "         34: 477,\n",
              "         35: 10,\n",
              "         36: 18,\n",
              "         37: 11,\n",
              "         38: 6,\n",
              "         39: 12,\n",
              "         40: 13,\n",
              "         41: 10,\n",
              "         42: 29,\n",
              "         43: 25,\n",
              "         44: 27,\n",
              "         45: 14,\n",
              "         46: 22,\n",
              "         47: 10,\n",
              "         48: 61,\n",
              "         49: 42,\n",
              "         50: 18,\n",
              "         51: 21,\n",
              "         52: 60,\n",
              "         53: 34,\n",
              "         54: 19,\n",
              "         55: 37,\n",
              "         56: 22,\n",
              "         57: 92,\n",
              "         58: 14,\n",
              "         59: 25,\n",
              "         60: 18,\n",
              "         61: 14,\n",
              "         62: 35,\n",
              "         63: 64,\n",
              "         64: 13,\n",
              "         65: 46,\n",
              "         66: 10,\n",
              "         67: 95,\n",
              "         68: 63,\n",
              "         69: 24,\n",
              "         70: 29,\n",
              "         71: 11,\n",
              "         72: 29,\n",
              "         73: 113,\n",
              "         74: 164,\n",
              "         75: 12,\n",
              "         76: 7,\n",
              "         77: 42,\n",
              "         78: 63,\n",
              "         79: 7,\n",
              "         80: 16,\n",
              "         81: 12,\n",
              "         82: 9,\n",
              "         83: 10})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "Counter(train_dataset.targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ47FgSMZszS"
      },
      "source": [
        "1. Разбиение на тренировучную и на валидационную выборки, на тест. Для каждый достоприм. -> [Train_imgs, val_imgs]\n",
        "\n",
        "2. Сохранять веса модели в процессе обучения torch.save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GCB52EBkBBQ"
      },
      "outputs": [],
      "source": [
        "train_triplet_dataset = create_triplets(train_dataset)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_triplet_dataset, batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHk8OOfSbXKC"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model = ResNet()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "criterion = TripletLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRSU3Ks2bwq6"
      },
      "outputs": [],
      "source": [
        "anchor, positive, negative = train_triplet_dataset[0]\n",
        "\n",
        "print(anchor.shape)\n",
        "print(positive.shape)\n",
        "print(negative.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6w1M9iggsY3"
      },
      "outputs": [],
      "source": [
        "for inputs in train_dataloader:\n",
        "    inputs_0 = inputs[0].to(device)\n",
        "    inputs_1 = inputs[1].to(device)\n",
        "    inputs_2 = inputs[2].to(device)\n",
        "    outputs_0 = model(inputs_0)\n",
        "    outputs_1 = model(inputs_1)\n",
        "    outputs_2 = model(inputs_2)\n",
        "    \n",
        "    loss = criterion(outputs_0, outputs_1, outputs_2)\n",
        "    print(loss)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yXCLtHrVFNV"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) #Adam \n",
        "train_model(model, criterion, optimizer, train_dataloader, num_epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Js9Mxe2leGtX"
      },
      "outputs": [],
      "source": [
        "model_path = '/content/model.pt'\n",
        "# torch.save(model.state_dict(), model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "ffbabbbebd0f49a097f22201fbddcf4b",
            "4f80fa17239b4d77a59ddaabd0aba659",
            "fcde2cc4598541ed9dc9f46b9ea9ea3e",
            "73ed5aef0f3e4e30962cb0421ba68494",
            "1a47407f470446dc9a1afb9ac04d14d4",
            "df9de140ee5b43f492a81e3f5e879ba7",
            "1b6b39b232f941cda1d779f214adb92b",
            "df5c465acb5f43cba41e93685b13e1a3",
            "8f6cf8cf02d546ea9eacc977770046b9",
            "bb05218273134f718f50ab1dec7f6e92",
            "dee508107f714e75b10253d9d2c5630f"
          ]
        },
        "id": "FUhcqEgneGtY",
        "outputId": "8a8ce293-d03b-464a-95c6-96d8f9b0ae41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffbabbbebd0f49a097f22201fbddcf4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model = ResNet()\n",
        "model.load_state_dict(torch.load(model_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cHzt2ydeGtY",
        "outputId": "46098c71-ecde-45ea-d8ed-bb0ac6976ccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted classification of the image is: Synagogue\n"
          ]
        }
      ],
      "source": [
        "image = Image.open('pn_ev_kirche_brandenburgerstr1_1920a.jpg') # Replace with your own image path\n",
        "\n",
        "# Preprocess the image\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    # transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "image_tensor = transform(image)\n",
        "image_tensor = image_tensor.unsqueeze(0)\n",
        "\n",
        "# Make a prediction\n",
        "with torch.no_grad():\n",
        "    output = model(image_tensor)\n",
        "prediction = torch.argmax(output).item()\n",
        "\n",
        "# Get the predicted class name\n",
        "predicted_class = train_dataset.classes[prediction]\n",
        "\n",
        "print('The predicted classification of the image is:', predicted_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TiOc7pOeGtZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ffbabbbebd0f49a097f22201fbddcf4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f80fa17239b4d77a59ddaabd0aba659",
              "IPY_MODEL_fcde2cc4598541ed9dc9f46b9ea9ea3e",
              "IPY_MODEL_73ed5aef0f3e4e30962cb0421ba68494"
            ],
            "layout": "IPY_MODEL_1a47407f470446dc9a1afb9ac04d14d4"
          }
        },
        "4f80fa17239b4d77a59ddaabd0aba659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df9de140ee5b43f492a81e3f5e879ba7",
            "placeholder": "​",
            "style": "IPY_MODEL_1b6b39b232f941cda1d779f214adb92b",
            "value": "100%"
          }
        },
        "fcde2cc4598541ed9dc9f46b9ea9ea3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df5c465acb5f43cba41e93685b13e1a3",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f6cf8cf02d546ea9eacc977770046b9",
            "value": 46830571
          }
        },
        "73ed5aef0f3e4e30962cb0421ba68494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb05218273134f718f50ab1dec7f6e92",
            "placeholder": "​",
            "style": "IPY_MODEL_dee508107f714e75b10253d9d2c5630f",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 110MB/s]"
          }
        },
        "1a47407f470446dc9a1afb9ac04d14d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df9de140ee5b43f492a81e3f5e879ba7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b6b39b232f941cda1d779f214adb92b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df5c465acb5f43cba41e93685b13e1a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f6cf8cf02d546ea9eacc977770046b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb05218273134f718f50ab1dec7f6e92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dee508107f714e75b10253d9d2c5630f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}